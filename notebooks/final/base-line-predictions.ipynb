{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "611f079f",
   "metadata": {},
   "source": [
    "# Base-Line Model Predictions with Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c73c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ded7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df_raw = pd.read_csv('/Users/thananpornsethjinda/Desktop/internship/projects/titanic-survival-prediction/data/train.csv')\n",
    "test_df_raw = pd.read_csv('/Users/thananpornsethjinda/Desktop/internship/projects/titanic-survival-prediction/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_dataframe(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # log helper\n",
    "    def log(msg):\n",
    "        if verbose:\n",
    "            print(f\"[INFO] {msg}\")\n",
    "\n",
    "    # 1. standardize column names\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    log(\"Standardized column names.\")\n",
    "\n",
    "    # 2. remove exact duplicates\n",
    "    dup_count = df.duplicated().sum()\n",
    "    if dup_count > 0:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        log(f\"Removed {dup_count} duplicate rows.\")\n",
    "\n",
    "    # 3. trim and lowercase all string (object) values\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "    log(\"Standardized string columns (lowercase + trimmed).\")\n",
    "\n",
    "    # 4. detect missing values (including blanks and placeholders)\n",
    "    placeholder_values = ['n/a', 'na', '--', '-', 'none', 'null', '', 'nan']\n",
    "    df.replace(placeholder_values, np.nan, inplace=True)\n",
    "    null_report = df.isnull().sum()\n",
    "    null_report = null_report[null_report > 0]\n",
    "    if not null_report.empty:\n",
    "        log(f\"Missing values found in columns:\\n{null_report}\")\n",
    "\n",
    "    # 5. flag constant columns\n",
    "    constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    if constant_cols:\n",
    "        log(f\"Constant columns (consider removing): {constant_cols}\")\n",
    "\n",
    "    # 6. flag high cardinality categorical columns\n",
    "    high_card_cols = [col for col in df.select_dtypes(include='object') if df[col].nunique() > 100]\n",
    "    if high_card_cols:\n",
    "        log(f\"High-cardinality columns (consider encoding strategies): {high_card_cols}\")\n",
    "\n",
    "    # 7. detect numeric outliers using IQR\n",
    "    num_cols = df.select_dtypes(include=np.number).columns\n",
    "    outlier_report = {}\n",
    "    for col in num_cols:\n",
    "        q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        outliers = df[(df[col] < lower) | (df[col] > upper)][col].count()\n",
    "        if outliers > 0:\n",
    "            outlier_report[col] = outliers\n",
    "    if outlier_report:\n",
    "        log(f\"Potential numeric outliers detected:\\n{outlier_report}\")\n",
    "    \n",
    "    # 8. convert applicable columns to category\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        n_unique = df[col].nunique()\n",
    "        if n_unique < len(df) * 0.05:\n",
    "            df[col] = df[col].astype('category')\n",
    "    log(\"Converted suitable object columns to category dtype.\")\n",
    "\n",
    "    log(\"Data cleaning complete.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded17a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Standardized column names.\n",
      "[INFO] Standardized string columns (lowercase + trimmed).\n",
      "[INFO] Missing values found in columns:\n",
      "age         177\n",
      "cabin       687\n",
      "embarked      2\n",
      "dtype: int64\n",
      "[INFO] High-cardinality columns (consider encoding strategies): ['name', 'ticket', 'cabin']\n",
      "[INFO] Potential numeric outliers detected:\n",
      "{'age': np.int64(11), 'sibsp': np.int64(46), 'parch': np.int64(213), 'fare': np.int64(116)}\n",
      "[INFO] Converted suitable object columns to category dtype.\n",
      "[INFO] Data cleaning complete.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[INFO] Standardized column names.\n",
      "[INFO] Standardized string columns (lowercase + trimmed).\n",
      "[INFO] Missing values found in columns:\n",
      "age       86\n",
      "fare       1\n",
      "cabin    327\n",
      "dtype: int64\n",
      "[INFO] High-cardinality columns (consider encoding strategies): ['name', 'ticket']\n",
      "[INFO] Potential numeric outliers detected:\n",
      "{'age': np.int64(2), 'sibsp': np.int64(11), 'parch': np.int64(94), 'fare': np.int64(55)}\n",
      "[INFO] Converted suitable object columns to category dtype.\n",
      "[INFO] Data cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_val_df = clean_dataframe(train_val_df_raw)\n",
    "\n",
    "print(\"-\" * 100)\n",
    "\n",
    "test_df = clean_dataframe(test_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc249cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df[['pclass', 'sex', 'age', 'embarked']], train_df['survived']\n",
    "X_val, y_val = val_df[['pclass', 'sex', 'age', 'embarked']], val_df['survived']\n",
    "X_test = test_df[['pclass', 'sex', 'age', 'embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c9e9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass     sex   age embarked\n",
       "331       1    male  45.5        s\n",
       "733       2    male  23.0        s\n",
       "382       3    male  32.0        s\n",
       "704       3    male  26.0        s\n",
       "813       3  female   6.0        s\n",
       "..      ...     ...   ...      ...\n",
       "106       3  female  21.0        s\n",
       "270       1    male   NaN        s\n",
       "860       3    male  41.0        s\n",
       "435       1  female  14.0        s\n",
       "102       1    male  21.0        s\n",
       "\n",
       "[712 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d53ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'embarked', 'pclass']\n",
    "\n",
    "NUMERICAL_COLUMNS = ['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d48275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9445901",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps = [\n",
    "    ('impute', SimpleImputer(strategy='mean')), \n",
    "    ('scale', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcf3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline(steps = [\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one-hot-encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba84cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "col_transformer = ColumnTransformer(transformers = [\n",
    "    ('num-pipeline', num_pipeline, NUMERICAL_COLUMNS),\n",
    "    ('cat-pipeline', cat_pipeline, CATEGORICAL_COLUMNS)\n",
    "], \n",
    "    remainder='drop',\n",
    "    n_jobs=-1                                 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fda2ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "def fit_and_print(p, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val):\n",
    "\n",
    "    p.fit(X_train, y_train) \n",
    "    train_preds = p.predict(X_train)\n",
    "    val_preds = p.predict(X_val)\n",
    "    print(\"Training Error:\")\n",
    "    print(confusion_matrix(y_train, train_preds, normalize='true'))\n",
    "    print(f1_score(y_train, train_preds))\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Validation Error:\")\n",
    "    print(confusion_matrix(y_val, val_preds, normalize='true'))\n",
    "    print(f1_score(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23b3143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aebd3a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "[[0.85135135 0.14864865]\n",
      " [0.29850746 0.70149254]]\n",
      "0.7203065134099617\n",
      "------------------------------\n",
      "Validation Error:\n",
      "[[0.83809524 0.16190476]\n",
      " [0.27027027 0.72972973]]\n",
      "0.7448275862068966\n"
     ]
    }
   ],
   "source": [
    "### Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "p_lr = make_pipeline(col_transformer, lr)\n",
    "\n",
    "### Performance \n",
    "\n",
    "fit_and_print(p_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9520a6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "[[0.85135135 0.14864865]\n",
      " [0.31716418 0.68283582]]\n",
      "0.7079303675048356\n",
      "------------------------------\n",
      "Validation Error:\n",
      "[[0.83809524 0.16190476]\n",
      " [0.27027027 0.72972973]]\n",
      "0.7448275862068966\n"
     ]
    }
   ],
   "source": [
    "### LDA \n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "\n",
    "p_lda = make_pipeline(col_transformer, lda)\n",
    "\n",
    "### Performance \n",
    "\n",
    "fit_and_print(p_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d859f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "[[0.95495495 0.04504505]\n",
      " [0.19029851 0.80970149]]\n",
      "0.8594059405940594\n",
      "------------------------------\n",
      "Validation Error:\n",
      "[[0.80952381 0.19047619]\n",
      " [0.25675676 0.74324324]]\n",
      "0.738255033557047\n"
     ]
    }
   ],
   "source": [
    "### Random Forests \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "p_rfc = make_pipeline(col_transformer, rfc)\n",
    "\n",
    "### Performance \n",
    "\n",
    "fit_and_print(p_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "026772c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "[[0.90315315 0.09684685]\n",
      " [0.2238806  0.7761194 ]]\n",
      "0.8015414258188824\n",
      "------------------------------\n",
      "Validation Error:\n",
      "[[0.84761905 0.15238095]\n",
      " [0.31081081 0.68918919]]\n",
      "0.723404255319149\n"
     ]
    }
   ],
   "source": [
    "### KNN \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knnc = KNeighborsClassifier()\n",
    "\n",
    "p_knnc = make_pipeline(col_transformer, knnc)\n",
    "\n",
    "### Performance \n",
    "\n",
    "fit_and_print(p_knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6441fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = p_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93f9f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_df_raw.PassengerId, 'Survived': test_predictions})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
